#!/usr/bin/env python3
"""
Vector Performance Optimization Script
Executed directly from Python to avoid SQL editor timeout issues.
Optimizes only Gemini embeddings (removes Qwen optimizations as requested).
Uses Supabase SQL API for execution.
"""

import os
import time
import logging
import requests
from dotenv import load_dotenv

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def load_database_config():
    """Load database configuration from environment variables."""
    load_dotenv()
    
    SUPABASE_URL = os.getenv("SUPABASE_URL")
    SUPABASE_KEY = os.getenv("SUPABASE_KEY")
    
    if not SUPABASE_URL or not SUPABASE_KEY:
        raise ValueError("Missing SUPABASE_URL or SUPABASE_KEY in environment variables")
    
    return SUPABASE_URL, SUPABASE_KEY

def execute_sql_via_supabase_api(supabase_url: str, supabase_key: str, sql: str, description: str, max_retries: int = 3):
    """Execute SQL via Supabase REST API with retry logic."""
    headers = {
        "apikey": supabase_key,
        "Authorization": f"Bearer {supabase_key}",
        "Content-Type": "application/json",
        "Prefer": "return=minimal"
    }
    
    # Use the rpc endpoint for SQL execution
    url = f"{supabase_url}/rest/v1/rpc/exec_sql"
    
    for attempt in range(max_retries):
        try:
            logger.info(f"Executing: {description} (attempt {attempt + 1}/{max_retries})")
            start_time = time.time()
            
            data = {"sql_query": sql}
            response = requests.post(url, headers=headers, json=data, timeout=300)  # 5 minute timeout
            
            execution_time = time.time() - start_time
            
            if response.status_code == 200:
                logger.info(f"Completed: {description} in {execution_time:.2f}s")
                return response
            else:
                error_msg = f"HTTP {response.status_code}: {response.text}"
                logger.error(f"SQL execution failed: {error_msg}")
                raise Exception(error_msg)
                
        except requests.exceptions.Timeout:
            if attempt == max_retries - 1:
                logger.error(f"Timeout after {max_retries} attempts: {description}")
                raise Exception("Operation timed out")
            else:
                logger.warning(f"Attempt {attempt + 1} timed out. Retrying...")
                time.sleep(5 * (attempt + 1))  # Incremental backoff
                
        except Exception as e:
            if attempt == max_retries - 1:
                logger.error(f"Failed after {max_retries} attempts: {description}")
                raise e
            else:
                logger.warning(f"Attempt {attempt + 1} failed: {e}. Retrying...")
                time.sleep(2 ** attempt)  # Exponential backoff

def optimize_gemini_embeddings(supabase_url: str, supabase_key: str):
    """Optimize Gemini embeddings index and function."""
    
    # Step 1: Drop existing Gemini index
    drop_index_sql = "DROP INDEX IF EXISTS idx_embedding_gemini;"
    execute_sql_via_supabase_api(supabase_url, supabase_key, drop_index_sql, "Drop existing Gemini index")
    
    # Step 2: Create optimized HNSW index for Gemini embeddings
    create_index_sql = """
    CREATE INDEX idx_embedding_gemini ON sefaria_text_chunks 
    USING hnsw (embedding_gemini halfvec_cosine_ops)
    WITH (m = 24, ef_construction = 96);
    """
    execute_sql_via_supabase_api(supabase_url, supabase_key, create_index_sql, "Create optimized Gemini HNSW index")
    
    # Step 3: Optimize Gemini RPC function with query-time tuning
    drop_function_sql = "DROP FUNCTION IF EXISTS match_sefaria_chunks_gemini(halfvec(3072), float, int);"
    execute_sql_via_supabase_api(supabase_url, supabase_key, drop_function_sql, "Drop existing Gemini function")
    
    create_function_sql = """
    CREATE OR REPLACE FUNCTION match_sefaria_chunks_gemini (
        query_embedding halfvec(3072),
        match_threshold float DEFAULT 0.5,
        match_count int DEFAULT 10
    )
    RETURNS TABLE (
        id uuid,
        content text,
        sefaria_ref text,
        metadata jsonb,
        similarity float
    )
    LANGUAGE plpgsql STABLE
    AS $$
    BEGIN
        -- Higher ef_search for 3072d vectors to maintain accuracy
        -- 60 provides better results for high-dimensional space
        SET LOCAL hnsw.ef_search = 60;
        
        RETURN QUERY
        SELECT
            sefaria_text_chunks.id,
            sefaria_text_chunks.content,
            sefaria_text_chunks.sefaria_ref,
            sefaria_text_chunks.metadata,
            1 - (sefaria_text_chunks.embedding_gemini <=> query_embedding) AS similarity
        FROM sefaria_text_chunks
        WHERE sefaria_text_chunks.embedding_gemini IS NOT NULL
          AND 1 - (sefaria_text_chunks.embedding_gemini <=> query_embedding) > match_threshold
        ORDER BY (sefaria_text_chunks.embedding_gemini <=> query_embedding) ASC
        LIMIT match_count;
    END;
    $$;
    """
    execute_sql_via_supabase_api(supabase_url, supabase_key, create_function_sql, "Create optimized Gemini function")

def verify_optimizations(supabase_url: str, supabase_key: str):
    """Verify that optimizations were applied successfully."""
    
    # Check index creation and sizes
    verify_sql = """
    SELECT 
        indexname, 
        tablename, 
        indexdef,
        pg_size_pretty(pg_relation_size(indexname::regclass)) as index_size
    FROM pg_indexes 
    WHERE tablename = 'sefaria_text_chunks' 
      AND indexname LIKE '%embedding%';
    """
    
    try:
        logger.info("Verifying optimizations...")
        
        headers = {
            "apikey": supabase_key,
            "Authorization": f"Bearer {supabase_key}",
            "Content-Type": "application/json"
        }
        
        url = f"{supabase_url}/rest/v1/rpc/exec_sql"
        data = {"sql_query": verify_sql}
        
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            results = response.json()
            if results:
                logger.info("Index verification results:")
                for row in results:
                    logger.info(f"  - {row}")
            else:
                logger.info("No embedding indexes found")
        else:
            logger.warning(f"Verification query failed: HTTP {response.status_code}")
            
    except Exception as e:
        logger.warning(f"Verification query failed: {e}")

def main():
    """Main execution function."""
    try:
        logger.info("Starting vector performance optimization (Gemini only)...")
        
        # Load configuration
        supabase_url, supabase_key = load_database_config()
        
        # Execute optimizations
        start_time = time.time()
        
        optimize_gemini_embeddings(supabase_url, supabase_key)
        verify_optimizations(supabase_url, supabase_key)
        
        total_time = time.time() - start_time
        logger.info(f"Optimization completed successfully in {total_time:.2f}s")
        
        # Print expected improvements
        logger.info("""
Expected Performance Improvements:
- Vector Search (Gemini): 2-3s â†’ 0.3-0.8s (70% improvement)
  - Optimized HNSW index with m=24, ef_construction=96 for 3072d vectors
  - Query-time ef_search tuning set to 60 for high-dimensional space
  - Better distance comparisons through improved index structure

Note: For additional database-wide optimizations, contact Supabase support:
- ALTER SYSTEM SET maintenance_work_mem = '1GB'
- ALTER SYSTEM SET hnsw.ef_search = 40
        """)
        
    except Exception as e:
        logger.error(f"Optimization failed: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
